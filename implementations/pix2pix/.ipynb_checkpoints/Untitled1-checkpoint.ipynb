{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models import *\n",
    "from datasets import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_epoch = 180\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "generator = GeneratorUNet(in_channels=1, out_channels=1)\n",
    "if cuda:\n",
    "    generator = generator.cuda()\n",
    "generator.load_state_dict(torch.load('saved_models/sparse2dense/generator_%d.pth'%(model_epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_B = [ transforms.Resize((256, 256), Image.BICUBIC),\n",
    "                transforms.ToTensor() ]\n",
    "data_transform = transforms.Compose(transforms_B)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0015, 0.0010, 0.0005,  ..., 0.0004, 0.0007, 0.0014],\n",
      "         [0.0006, 0.0003, 0.0001,  ..., 0.0001, 0.0005, 0.0007],\n",
      "         [0.0006, 0.0003, 0.0002,  ..., 0.0003, 0.0006, 0.0007],\n",
      "         ...,\n",
      "         [0.0041, 0.0040, 0.0040,  ..., 0.0039, 0.0040, 0.0040],\n",
      "         [0.0042, 0.0041, 0.0041,  ..., 0.0039, 0.0041, 0.0041],\n",
      "         [0.0042, 0.0040, 0.0040,  ..., 0.0040, 0.0041, 0.0041]]])\n",
      "Hz:  43.00482923378208\n"
     ]
    }
   ],
   "source": [
    "def sample_images():\n",
    "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
    "    prev_time = time.time()\n",
    "    image = cv2.imread(\"/media/arg_ws3/5E703E3A703E18EB/data/sparse2dense/pcl/pcl_31.png\",-1)\n",
    "    pil_im = Image.fromarray(image)\n",
    "    pil_im = data_transform(pil_im)\n",
    "    pil_im = pil_im.unsqueeze(0)\n",
    "\n",
    "    my_img = Variable(pil_im.type(Tensor))\n",
    "    my_img_fake = generator(my_img)\n",
    "    my_img_fake = my_img_fake.squeeze(0).detach().cpu()\n",
    "    \n",
    "    print(my_img_fake)\n",
    "\n",
    "    pil_ = my_img_fake.mul(255).clamp(0, 255).to(torch.float32).permute(1, 2, 0)\n",
    "    pil_ = np.array(pil_)\n",
    "    pil_ = pil_[...,::-1]\n",
    "    pil_ = cv2.resize(pil_, (640, 480))\n",
    "    cv2.imwrite(\"dep.png\", pil_)\n",
    "    print(\"Hz: \", 1./(time.time() - prev_time))\n",
    "sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint16\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "tensor([[[[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,  ..., -11.2986, -34.5898, -38.3529],\n",
      "          ...,\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "gt_img = cv2.imread(\"/media/arg_ws3/5E703E3A703E18EB/data/sparse2dense/pcl/img_1263.png\",cv2.IMREAD_UNCHANGED)\n",
    "print(gt_img.dtype)\n",
    "print(gt_img)\n",
    "'''for i in range(480):\n",
    "    for j in range(480):\n",
    "        if(gt_img[i][j]!=0 and gt_img[i][j]>1000):\n",
    "            print(gt_img[i][j])'''\n",
    "gt_img = np.float32(gt_img)\n",
    "print(gt_img)\n",
    "pil_gt = Image.fromarray(gt_img)\n",
    "pil_gt = data_transform(pil_gt)\n",
    "pil_gt = pil_gt.unsqueeze(0)\n",
    "print(pil_gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
