{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3829, 3829, 3829, ..., 2236, 2236, 2228],\n",
       "       [3829, 3829, 3853, ..., 2236, 2236, 2228],\n",
       "       [3829, 3829, 3853, ..., 2236, 2236, 2228],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  279,  279,  279],\n",
       "       [   0,    0,    0, ...,  279,  279,  279],\n",
       "       [   0,    0,    0, ...,  279,  279,  279]], dtype=int32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/media/arg_ws3/5E703E3A703E18EB/data/subt_real_ssd/JPEGImages/scene000001_4.png'\n",
    "img = Image.open(path)\n",
    "img = np.array(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3829, 0.3829, 0.3829, ..., 0.2236, 0.2236, 0.2228],\n",
       "       [0.3829, 0.3829, 0.3853, ..., 0.2236, 0.2236, 0.2228],\n",
       "       [0.3829, 0.3829, 0.3853, ..., 0.2236, 0.2236, 0.2228],\n",
       "       ...,\n",
       "       [0.    , 0.    , 0.    , ..., 0.0279, 0.0279, 0.0279],\n",
       "       [0.    , 0.    , 0.    , ..., 0.0279, 0.0279, 0.0279],\n",
       "       [0.    , 0.    , 0.    , ..., 0.0279, 0.0279, 0.0279]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img/10000.\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Compose([ \n",
    "                transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                             std = [ 1/0.5, 1/0.5, 1/0.5 ]),\n",
    "                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ],\n",
    "                                             std = [ 1., 1., 1. ]),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = Image.fromarray(img)\n",
    "transforms_ = [ transforms.Resize((256, 256), Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "transform_img = transforms.Compose(transforms_)\n",
    "pil_img = transform_img(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3828, 0.3849, 0.3895,  ..., 0.2261, 0.2242, 0.2233],\n",
       "         [0.3850, 0.3878, 0.3916,  ..., 0.2261, 0.2242, 0.2233],\n",
       "         [0.3920, 0.3924, 0.3951,  ..., 0.2261, 0.2243, 0.2231],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0180, 0.0142, 0.0193],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0299, 0.0286, 0.0290],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0280, 0.0279, 0.0279]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_img = pil_img.cpu().detach()\n",
    "pil_img = inv_normalize(pil_img)\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = pil_img.mul(10000).clamp(0, 10000).to(torch.int16).permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_img = (np.array(pil_img)*10000).astype(np.uint16)\n",
    "cv_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
